<% if @grammar.modulename %>
module <%= @grammar.modulename %>;

<% end %>
class <%= classname %>
{
    class Decoder
    {
        enum
        {
            CODE_POINT_INVALID = 0xFFFFFFFE,
            CODE_POINT_EOF = 0xFFFFFFFF,
        }

        static uint decode_code_point(const(ubyte) * input, size_t input_length, size_t * code_point_length)
        {
            if (input_length == 0u)
            {
                return CODE_POINT_EOF;
            }
            ubyte c = *input;
            uint result;
            if ((c & 0x80u) == 0u)
            {
                result = c;
                *code_point_length = 1u;
            }
            else
            {
                ubyte following_bytes;
                if ((c & 0xE0u) == 0xC0u)
                {
                    result = c & 0x1Fu;
                    following_bytes = 1u;
                }
                else if ((c & 0xF0u) == 0xE0u)
                {
                    result = c & 0x0Fu;
                    following_bytes = 2u;
                }
                else if ((c & 0xF8u) == 0xF0u)
                {
                    result = c & 0x07u;
                    following_bytes = 3u;
                }
                else if ((c & 0xFCu) == 0xF8u)
                {
                    result = c & 0x03u;
                    following_bytes = 4u;
                }
                else if ((c & 0xFEu) == 0xFCu)
                {
                    result = c & 0x01u;
                    following_bytes = 5u;
                }
                if (input_length <= following_bytes)
                {
                    return CODE_POINT_INVALID;
                }
                *code_point_length = following_bytes + 1u;
                while (following_bytes-- > 0u)
                {
                    input++;
                    result <<= 6u;
                    result |= *input & 0x3Fu;
                }
            }
            return result;
        }
    }

    class Lexer
    {
        enum
        {
<% @grammar.tokens.each_with_index do |token, index| %>
<%   if token.name %>
            TOKEN_<%= token.c_name %> = <%= index %>,
<%   end %>
<% end %>
            TOKEN_EOF = <%= TOKEN_EOF %>,
            TOKEN_DECODE_ERROR = <%= TOKEN_DECODE_ERROR %>,
            TOKEN_DROP = <%= TOKEN_DROP %>,
            TOKEN_NONE = <%= TOKEN_NONE %>,
        }

        static immutable string TokenNames[] = [
<% @grammar.tokens.each_with_index do |token, index| %>
<%   if token.name %>
            "<%= token.name %>",
<%   else %>
            null,
<%   end %>
<% end %>
        ];

        private struct Transition
        {
            uint first;
            uint last;
            uint destination;
        }

        private struct State
        {
            uint transition_table_index;
            uint n_transitions;
            uint accepts;
        }

<% transition_table, state_table = lexer_dfa.build_tables %>
        private static const Transition transitions[] = [
<% transition_table.each do |transition_table_entry| %>
            Transition(<%= transition_table_entry[:first] %>u, <%= transition_table_entry[:last] %>u, <%= transition_table_entry[:destination] %>u),
<% end %>
        ];

        private static const State states[] = [
<% state_table.each do |state_table_entry| %>
            State(<%= state_table_entry[:transition_table_index] %>u, <%= state_table_entry[:n_transitions] %>u, <%= state_table_entry[:accepts] %>u),
<% end %>
        ];

        struct LexedToken
        {
            size_t row;
            size_t col;
            uint token;
        }

        private const(ubyte) * m_input;
        private size_t m_input_length;
        private size_t m_input_position;
        private size_t m_input_row;
        private size_t m_input_col;

        this(const(ubyte) * input, size_t input_length)
        {
            m_input = input;
            m_input_length = input_length;
        }

        LexedToken lex_token()
        {
            for (;;)
            {
                LexedToken lt = attempt_lex_token();
                if (lt.token != TOKEN_DROP)
                {
                    return lt;
                }
            }
        }

        private LexedToken attempt_lex_token()
        {
            LexedToken lt = LexedToken(m_input_row, m_input_col, TOKEN_NONE);
            struct LexedTokenState
            {
                size_t length;
                size_t delta_row;
                size_t delta_col;
                uint token;
            }
            LexedTokenState last_accepts_info;
            last_accepts_info.token = TOKEN_NONE;
            LexedTokenState attempt_info;
            uint current_state;
            for (;;)
            {
                size_t code_point_length;
                uint code_point = Decoder.decode_code_point(&m_input[m_input_position], m_input_length - m_input_position, &code_point_length);
                if (code_point == Decoder.CODE_POINT_INVALID)
                {
                    lt.token = TOKEN_DECODE_ERROR;
                    return lt;
                }
                bool lex_continue = false;
                if (code_point != Decoder.CODE_POINT_EOF)
                {
                    uint dest = transition(current_state, code_point);
                    if (dest != cast(uint)-1)
                    {
                        lex_continue = true;
                        attempt_info.length += code_point_length;
                        if (code_point == '\n')
                        {
                            attempt_info.delta_row++;
                            attempt_info.delta_col = 0u;
                        }
                        else
                        {
                            attempt_info.delta_col++;
                        }
                        current_state = dest;
                        if (states[current_state].accepts != TOKEN_NONE)
                        {
                            attempt_info.token = states[current_state].accepts;
                            last_accepts_info = attempt_info;
                        }
                    }
                }
                if (!lex_continue)
                {
                    if (last_accepts_info.token != TOKEN_NONE)
                    {
                        lt.token = last_accepts_info.token;
                        m_input_position += last_accepts_info.length;
                        m_input_row += last_accepts_info.delta_row;
                        if (last_accepts_info.delta_row != 0u)
                        {
                            m_input_col = last_accepts_info.delta_col;
                        }
                        else
                        {
                            m_input_col += last_accepts_info.delta_col;
                        }
                    }
                    break;
                }
            }
            return lt;
        }

        private uint transition(uint current_state, uint code_point)
        {
            uint transition_table_index = states[current_state].transition_table_index;
            for (uint i = 0u; i < states[current_state].n_transitions; i++)
            {
                if ((transitions[transition_table_index].first <= code_point) &&
                    (code_point <= transitions[transition_table_index].last))
                {
                    return transitions[transition_table_index].destination;
                }
            }
            return cast(uint)-1;
        }
    }
}
